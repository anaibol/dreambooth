#!/usr/bin/env python


import os

the_cache_dir = os.path.join(
    os.path.dirname(os.path.abspath(__file__)), "..", "stable-diffusion-v1-5-cache"
)
print(the_cache_dir)
os.environ["HF_HOME"] = the_cache_dir
os.makedirs(the_cache_dir, exist_ok=True)
import sys
import torch
from diffusers import StableDiffusionPipeline
from diffusers import (
    AutoencoderKL,
    DDIMScheduler,
    DDPMScheduler,
    StableDiffusionPipeline,
    UNet2DConditionModel,
)

from transformers import CLIPTextModel, CLIPTokenizer


vae_cache_dir = "sd-vae-ft-mse-cache"

os.makedirs(vae_cache_dir, exist_ok=True)

pipe = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    revision="fp16",
    torch_dtype=torch.float16,
    use_auth_token=sys.argv[1],
)

tokenizer = CLIPTokenizer.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    subfolder="tokenizer",
    revision="fp16",
    use_auth_token=sys.argv[1],
)

text_encoder = CLIPTextModel.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    subfolder="text_encoder",
    revision="fp16",
    use_auth_token=sys.argv[1],
)
vae = AutoencoderKL.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    subfolder="vae",
    revision="fp16",
    use_auth_token=sys.argv[1],
)
pretrained_vae = AutoencoderKL.from_pretrained(
    "stabilityai/sd-vae-ft-mse", subfolder=None, cache_dir=vae_cache_dir, revision=None
)
unet = UNet2DConditionModel.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    subfolder="unet",
    revision="fp16",
    use_auth_token=sys.argv[1],
)

noise_scheduler = DDPMScheduler.from_config(
    "runwayml/stable-diffusion-v1-5",
    subfolder="scheduler",
    use_auth_token=sys.argv[1],
)
